{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax.random import PRNGKey, multivariate_normal\n",
    "\n",
    "import pyhf\n",
    "pyhf.set_backend(\"jax\")\n",
    "\n",
    "\n",
    "def make_model(pars: jnp.array) -> pyhf.Model:\n",
    "    bounded_pars = jnp.where(pars > 10., 10., jnp.abs(pars))\n",
    "    u1, u2, d1, d2 = bounded_pars\n",
    "    u = jnp.array([u1, u2, -u1 - u2])\n",
    "    d = jnp.array([d1, d2, -d1 - d2])\n",
    "    \n",
    "    sig = jnp.array([2,5,10])\n",
    "    nominal = jnp.array([50, 50, 50])\n",
    "    up = jnp.array([50, 50, 50]) + u\n",
    "    down = jnp.array([50, 50, 50]) + d\n",
    "    \n",
    "    \n",
    "    m = {\n",
    "        'channels': [{'name': 'singlechannel',\n",
    "        'samples': [{'name': 'signal',\n",
    "            'data': sig,\n",
    "            'modifiers': [{'name': 'mu', 'type': 'normfactor', 'data': None}]},\n",
    "            {'name': 'background',\n",
    "            'data': nominal,\n",
    "            'modifiers': [\n",
    "                {'name': 'bkguncrt',\n",
    "            'type': 'histosys',\n",
    "            'data': {'hi_data': up, 'lo_data': down}\n",
    "            }]}]}]\n",
    "        }\n",
    "    return pyhf.Model(m, validate=False)\n",
    "    \n",
    "def fisher_info_covariance(bestfit_pars: jnp.array, m: pyhf.Model, observed_data: jnp.array) -> jnp.array:\n",
    "    return jnp.linalg.inv(jax.hessian(lambda lhood_pars: -m.logpdf(lhood_pars, observed_data)[0])(bestfit_pars))\n",
    "\n",
    "def gaussian_logpdf(bestfit_pars: jnp.array, data: jnp.array, cov: jnp.array) -> jnp.array:\n",
    "    return jax.scipy.stats.multivariate_normal.logpdf(data, bestfit_pars, cov)\n",
    "\n",
    "def model_gaussianity(m: pyhf.Model, bestfit_pars: jnp.array, cov_approx: jnp.array, observed_data: jnp.array) -> jnp.array:\n",
    "    # - compare the likelihood of the fitted model with a gaussian approximation that has the same MLE (fitted_pars)\n",
    "    # - do this across a number of points in parspace (sampled from the gaussian approx) and take the mean squared diff\n",
    "    # - centre the values wrt the best-fit vals to scale the differences \n",
    "    gaussian_parspace_samples = multivariate_normal(key=PRNGKey(1), mean=bestfit_pars, cov=cov_approx, shape=(100,))\n",
    "    \n",
    "    relative_nlls_model = jax.vmap(\n",
    "        lambda pars, data: -(m.logpdf(pars, data)[0] - m.logpdf(bestfit_pars, data)[0]), # scale origin to bestfit pars\n",
    "        in_axes=(0, None)\n",
    "    )(gaussian_parspace_samples, observed_data)\n",
    "    \n",
    "    relative_nlls_gaussian = jax.vmap(\n",
    "        lambda pars, data: -(gaussian_logpdf(pars, data, cov_approx) - gaussian_logpdf(bestfit_pars, data, cov_approx)), # data fixes the lhood shape\n",
    "        in_axes=(0, None)\n",
    "    )(gaussian_parspace_samples, bestfit_pars)\n",
    "    \n",
    "    diffs = relative_nlls_model-relative_nlls_gaussian\n",
    "    return jnp.mean(diffs[jnp.isfinite(diffs)]**2, axis=0)\n",
    "\n",
    "def metrics(bestfit_pars: jnp.array, m: pyhf.Model, observed_data: jnp.array) -> jnp.array:\n",
    "    cov_approx = fisher_info_covariance(bestfit_pars, m, observed_data)\n",
    "    mu_idx, y_idx = m.config.par_order.index('mu'), m.config.par_order.index('bkguncrt')\n",
    "    mu_uncert2 = cov_approx[mu_idx, mu_idx]\n",
    "    pull_width_metric2 = (1-cov_approx[y_idx, y_idx])**2\n",
    "    gaussianity = model_gaussianity(m, bestfit_pars, cov_approx, observed_data)\n",
    "    cls_obs = pyhf.infer.hypotest(1.0, observed_data, m, init_pars = [0.0,0.0])\n",
    "    \n",
    "    return dict(cls_obs = cls_obs, mu_uncert2=mu_uncert2, pull_width_metric2=pull_width_metric2, gaussianity=gaussianity)\n",
    "\n",
    "def pipeline(pars: jnp.array, observed_data: jnp.array) -> jnp.array:\n",
    "    m = make_model(pars)\n",
    "    data = jnp.concatenate((observed_data, jnp.array(m.config.auxdata)))\n",
    "    mle_pars = pyhf.infer.mle.fit(data, m, init_pars=[0., 0.])\n",
    "    \n",
    "    return metrics(mle_pars, m, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls_obs': DeviceArray(0.12815149, dtype=float64),\n",
       " 'mu_uncert2': DeviceArray(0.3875969, dtype=float64),\n",
       " 'pull_width_metric2': DeviceArray(4.93038066e-32, dtype=float64),\n",
       " 'gaussianity': DeviceArray(0.24232135, dtype=float64)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(pars = jnp.array([1.,-2., -1.,2]), observed_data = jnp.array([50,50,50]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gitlab-registry.cern.ch/ai-ml/kubeflow_images/pytorch-notebook-gpu-1.8.0:v0.6.1-30-python3.8",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
